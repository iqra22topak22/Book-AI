---
sidebar_position: 11
---

# Glossary of Robotics Terms

This glossary provides definitions for key terms used throughout the Physical AI & Humanoid Robotics course.

## A

**Action (ROS)**: A goal-oriented communication pattern for long-running tasks with feedback and cancellation capabilities.

**Artificial Intelligence (AI)**: The simulation of human intelligence in machines programmed to think and learn.

**Autonomous Mobile Robot (AMR)**: A robot that moves around a facility without human guidance, typically using sensors and algorithms to navigate.

## B

**Behavior Tree**: A hierarchical model used in AI to define the logic of a robot or NPC (non-player character).

**Biomechanics**: The study of the structure, function, and motion of the mechanical aspects of biological systems.

## C

**Cartesian Space**: The 3D space defined by X, Y, and Z coordinates, used to describe the position and orientation of a robot's end-effector.

**Computer Vision**: A field of artificial intelligence that trains computers to interpret and understand the visual world.

**Control System**: A system that manages, commands, directs, or regulates the behavior of other devices or systems.

**Convolutional Neural Network (CNN)**: A class of deep neural networks, commonly used in image analysis.

## D

**Deep Learning**: A subset of machine learning that uses multi-layered neural networks to analyze various factors with a structure approach similar to human thinking.

**Degrees of Freedom (DOF)**: The number of independent movements a mechanical device can make.

**Digital Twin**: A virtual replica of a physical system that can be used to simulate, predict, and optimize performance.

**Dynamixel**: A series of smart actuators created by Robotis, popular in robotic applications for their precise control and feedback.

## E

**Embodied AI**: Artificial intelligence that is integrated into a physical system (robot) and learns through interaction with the real world.

**End Effector**: The device at the end of a robot arm that interacts with the environment, such as a gripper or tool.

**Euclidean Distance**: The ordinary straight-line distance between two points in Euclidean space.

## F

**Forward Kinematics**: The process used in robotics to determine the position and orientation of the end-effector based on the joint angles.

**Fiducial Marker**: A visual marker of known geometry and features that can be detected and analyzed in computer vision systems.

## G

**Gazebo**: An open-source 3D robotics simulator that provides realistic physics simulation and rendering.

**Generative Adversarial Network (GAN)**: A class of machine learning frameworks designed by Ian Goodfellow and colleagues in 2014.

**Geometric Transformation**: A bijection of a set that has a geometric structure to itself or another set, commonly used in robotics for coordinate system transformations.

## H

**Haptic Feedback**: Technology that recreates the sense of touch by applying forces, vibrations, or motions to the user.

**Human-Robot Interaction (HRI)**: A field of study that focuses on the design, development, and evaluation of robotic systems for human interaction.

**Hybrid Systems**: Systems that exhibit both continuous and discrete dynamic behavior.

## I

**Imu (Inertial Measurement Unit)**: An electronic device that measures and reports a body's specific force, angular rate, and sometimes the magnetic field.

**Inverse Kinematics**: The mathematical process of determining joint angles required to place the end-effector at a desired position and orientation.

**Isaac Sim**: NVIDIA's robotics simulator built on the Omniverse platform, designed for high-fidelity simulation and reinforcement learning.

**Isaac ROS**: NVIDIA's collection of hardware acceleration packages for robotics applications on ROS/ROS2.

## J

**Jacobian Matrix**: A matrix of all first-order partial derivatives of a vector-valued function, used in robotics to relate joint velocities to end-effector velocities.

**Joint Space**: The space defined by the joint angles of a robot manipulator.

## K

**Kinematics**: The branch of mechanics concerned with the motion of objects without reference to the forces that cause the motion.

**Kinetic Chain**: An assembly of rigid bodies connected by joints that transmit force and motion.

## L

**Legged Robot**: A robot that uses legs for locomotion, such as quadrupeds or bipeds.

**LiDAR (Light Detection and Ranging)**: A remote sensing method that uses light in the form of a pulsed laser to measure distances.

**Localization**: The ability of a robot to determine its position and orientation in a given space.

**Long Short-Term Memory (LSTM)**: A type of recurrent neural network capable of learning long-term dependencies.

## M

**Machine Learning**: A method of data analysis that automates analytical model building using algorithms that iteratively learn from data.

**Manipulation**: The branch of robotics dealing with the control of robotic hands and grasping objects.

**Mapping**: The process of creating a representation of the environment from sensor data in robotics.

**Marker Tracking**: The process of identifying and following a physical object with known geometry in computer vision.

**Monte Carlo Localization (MCL)**: A probabilistic algorithm for robot self-localization using particle filters.

## N

**Neural Network**: A series of algorithms that endeavors to recognize underlying relationships in a set of data through a process that mimics the way the human brain operates.

**Node (ROS)**: A process that performs computation in a ROS system.

**Non-holonomic Constraint**: A type of constraint that depends on the velocity of the system and cannot be integrated to a constraint that depends only on the coordinates.

## O

**Octree**: A tree data structure in which each internal node has exactly eight children, useful for 3D space partitioning in robotics.

**Odometry**: The use of data from motion sensors to estimate change in position over time.

**Omniview**: A camera system that can simultaneously view a 360-degree horizontal view around the camera.

**Omniverse**: NVIDIA's platform for 3D design collaboration and simulation.

## P

**Path Planning**: The computational process of determining a sequence of valid configurations that moves an object from an initial configuration to a goal configuration.

**Perception Stack**: The collection of algorithms and systems used by a robot to interpret sensory data from its environment.

**Point Cloud**: A collection of data points in 3D space, typically representing the external surfaces of objects.

**Pose**: The position and orientation of a rigid body in space.

**Proportional-Integral-Derivative (PID) Controller**: A control loop mechanism employing feedback for industrial control systems.

## R

**ROS (Robot Operating System)**: A flexible framework for writing robot software that provides a collection of tools, libraries, and conventions.

**ROS 2**: The second generation of the Robot Operating System, featuring improved security, scalability, and real-time capabilities.

**RRT (Rapidly-exploring Random Tree)**: A motion planning algorithm based on the construction of a rapidly exploring random tree.

**Raspberry Pi**: A series of small single-board computers developed to promote teaching of basic computer science in schools.

**Redundant Robot**: A robot with more degrees of freedom than required to perform a given task.

**Robotics Operating System (ROS)**: A framework for robot software development providing operating system-like functionality on a network of heterogeneous computers.

## S

**SLAM (Simultaneous Localization and Mapping)**: The computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location within it.

**Servo Motor**: A rotary actuator that allows for precise control of angular position, velocity, and acceleration.

**Simulation**: The imitation of the operation of a real-world process or system over time.

**Stereopsis**: The perception of depth and 3D structure obtained on the basis of binocular disparity.

**State Estimation**: The process of determining the state of a system from measurements, often using filters like Kalman or Particle filters.

## T

**Topic (ROS)**: A naming bus for data (messages) passing between nodes in ROS.

**Trajectory**: A path traced by a moving point, important in robot motion planning.

**Transform (TF)**: The relationship between two coordinate frames in terms of translation and rotation.

**Trust Region Policy Optimization (TRPO)**: A method for optimizing policies in reinforcement learning.

## V

**Velocity**: The rate of change of displacement with respect to time, important in robot motion control.

**Vision System**: A system that uses cameras and image processing to enable robots to "see" and interpret their environment.

**Voice Command Processing**: The process of converting spoken language to text and then interpreting the commands for robot execution.

**Vision-Language-Action (VLA)**: A multimodal system that integrates visual perception, language understanding, and physical action.

## W

**Waypoint**: A reference point in physical space used for route or path planning in navigation tasks.

**Wheel Odometry**: The use of data from wheel encoders to estimate the change in position over time of a wheeled robot.

**Whisper**: OpenAI's automatic speech recognition system that uses neural networks to convert speech to text.

## X, Y, Z

**XYZ Coordinate System**: A three-dimensional coordinate system using X, Y, and Z axes to define position in space.

**Yaw**: Rotation around the vertical (Z) axis of a vehicle or robot.

**Z-Buffer**: A memory buffer containing values for the Z-coordinate of each pixel in an image, used in 3D graphics for depth testing.